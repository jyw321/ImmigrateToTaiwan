---
title: "Text Analysis HK Newspaper"
author: "Po-Sheng Lee"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

```{r package}
library(pdftools)
library(tidyverse)
library(tm)
library(tmcn)
library(quanteda)
library(tidytext)
library(jiebaR)
library(wordcloud)
library(stringr)
library(httr)
library(rvest)
library(readtext)
library(magrittr)
library(knitr)
library(igraph)
library(ggraph)
library(extrafont)

```


# Import text corpus

Text is downloaded from WiseNews using keyword *移民台灣*. The news source include Ming Po, Apple Daily, Tai Gung, Wen Hui, Sin Dao, Metro, City, Orient. The time span is from 1998 to 2018.

```{r Import text data}

temp <- list.files(path = "text", pattern = "pdf$")
Rpdf <- readPDF(control = list(text = "-layout"))
textcorpus_hk <- Corpus(URISource(str_c("text/", temp)), 
                        readerControl = list(reader = Rpdf, language = "zh"))
## The first four character in ID is the year of text

workcorpus_hk <- tm_map(textcorpus_hk, removePunctuation) %>%
  tm_map(removeNumbers) %>%
  tm_map(function(word) {
    gsub("[A-Za-z0-9]", "", word)
  })


text_tidy_hk <- tidy(textcorpus_hk)
text_tidy_hk %<>%
  mutate(year = str_sub(meta(textcorpus_hk, tag = "id"), 1, 4), 
         publisher = str_match(text, "蘋果日報|明報|東方日報|星島日報|晴報|都市日報|大公報|文匯報")) %>%
  mutate(year = as.numeric(year)) %>%
  select(id, year, publisher, text)


## Taiwan News
temp2 <- list.files(path = "text_Taiwan", pattern = "pdf$")
textcorpus_tw <- Corpus(URISource(str_c("text_Taiwan/", temp2)), 
                        readerControl = list(reader = Rpdf, language = "zh"))

workcorpus_tw <- tm_map(textcorpus_tw, removePunctuation) %>%
  tm_map(removeNumbers) %>%
  tm_map(function(word) {
    gsub("[A-Za-z0-9]", "", word)
  })


text_tidy_tw <- tidy(textcorpus_tw)
text_tidy_tw %<>%
  mutate(year = str_sub(meta(textcorpus_tw, tag = "id"), 1, 4), 
         publisher = str_match(text,"Central\\sDaily|China\\sTimes|Commercial\\sTimes|Apple|Liberty|Udn|Economic\\sDaily")) %>%
  mutate(year = as.numeric(year)) %>%
  mutate(text = str_replace_all(text, "[A-Za-z0-9]", "")) %>%
  select(id, year, publisher, text)


```

```{r segment and stop}

seg <- worker(symbol = T, bylines = F, stop_word = "stopWords.txt")
idxhk <- seq_along(text_tidy_hk$text)
idxtw <- seq_along(text_tidy_tw$text)
for (i in idxhk){
    text_tidy_hk$text[i] <- text_tidy_hk$text[i] %>%
      segment(seg) %>% 
      paste(collapse = " ")
}
for (i in idxtw){
    text_tidy_tw$text[i] <- text_tidy_tw$text[i] %>%
      segment(seg) %>% 
      paste(collapse = " ")
}

corp_hk <- corpus(text_tidy_hk, docid_field = "id", text_field = "text") 
corp_tw <- corpus(text_tidy_tw, docid_field = "id", text_field = "text")

# use scan to create a character vector
chtr_stopwords <- scan("stopWords.txt", character(), quote = "") 

chtr_stopwords_hk <- c(chtr_stopwords, "內容", "服務", "提供", "電子", "版權", "使用者", "許可", 
                       "相關", "擁有", "機構", "引起", "負責", "責任", "保留", "報章", "權利", 
                       "承擔", "自行", "損失", "損害", "商標", "標記", "文章", "總數", "by", 
                       "日報", "蘋果", "king", "kong")

text_token_hk <- tokens(corp_hk, remove_punct = TRUE) %>%
  tokens_select(pattern = chtr_stopwords_hk, selection = "remove" )

text_token_tw <- tokens(corp_tw, remove_punct = TRUE) %>%
  tokens_select(pattern = chtr_stopwords, selection = "remove" )

text_dfm_hk <- dfm(text_token_hk) 
text_dfm_tw <- dfm(text_token_tw)

```

```{r frequency and wordcloud hk}

# the object of textstat is a dataframe, use the tidy method
text_dfm_hk %>%
  dfm_subset(year %in% c(1998:2002)) %>%
  textstat_frequency(n = 20) %>%
  ggplot(aes(x = reorder(feature, frequency), y = frequency)) +
  geom_point() +
  coord_flip() +
  labs(title = "1998-2002 word freq", x = NULL, y = "Frequency") +
  theme(text = element_text(family = "Heiti TC Light"))

text_dfm_hk %>%
  dfm_subset(year %in% c(2003:2007)) %>%
  textstat_frequency(n = 20) %>%
  ggplot(aes(x = reorder(feature, frequency), y = frequency)) +
  geom_point() +
  coord_flip() +
  labs(title = "2003-2007 word freq", x = NULL, y = "Frequency") +
  theme(text = element_text(family = "Heiti TC Light"))

text_dfm_hk %>%
  dfm_subset(year %in% c(2008:2012)) %>%
  textstat_frequency(n = 20) %>%
  ggplot(aes(x = reorder(feature, frequency), y = frequency)) +
  geom_point() +
  coord_flip() +
  labs(title = "2008-2012 word freq", x = NULL, y = "Frequency") +
  theme(text = element_text(family = "Heiti TC Light"))

text_dfm_hk %>%
  dfm_subset(year %in% c(2013:2017)) %>%
  textstat_frequency(n = 20) %>%
  ggplot(aes(x = reorder(feature, frequency), y = frequency)) +
  geom_point() +
  coord_flip() +
  labs(title = "2013-2017 word freq", x = NULL, y = "Frequency") +
  theme(text = element_text(family = "Heiti TC Light"))

```

```{r frequency and wordcloud tw}

text_dfm_tw %>%
  dfm_subset(year %in% c(1998:2002)) %>%
  textstat_frequency(n = 10) %>%
  ggplot(aes(x = reorder(feature, frequency), y = frequency)) +
  geom_point() +
  coord_flip() +
  labs(title = "1998-2002 word freq", x = NULL, y = "Frequency") +
  theme(text = element_text(family = "Heiti TC Light"))

text_dfm_tw %>%
  dfm_subset(year %in% c(2003:2007)) %>%
  textstat_frequency(n = 10) %>%
  ggplot(aes(x = reorder(feature, frequency), y = frequency)) +
  geom_point() +
  coord_flip() +
  labs(title = "2003-2007 word freq", x = NULL, y = "Frequency") +
  theme(text = element_text(family = "Heiti TC Light"))

text_dfm_tw %>%
  dfm_subset(year %in% c(2008:2012)) %>%
  textstat_frequency(n = 10) %>%
  ggplot(aes(x = reorder(feature, frequency), y = frequency)) +
  geom_point() +
  coord_flip() +
  labs(title = "2008-2012 word freq", x = NULL, y = "Frequency") +
  theme(text = element_text(family = "Heiti TC Light"))

text_dfm_tw %>%
  dfm_subset(year %in% c(2013:2017)) %>%
  textstat_frequency(n = 20) %>%
  ggplot(aes(x = reorder(feature, frequency), y = frequency)) +
  geom_point() +
  coord_flip() +
  labs(title = "2013-2017 word freq", x = NULL, y = "Frequency") +
  theme(text = element_text(family = "Heiti TC Light"))


```

```{r fcm and network}

text_fcm_hk_98 <- text_dfm_hk %>% #subset using dfm_subset
  dfm_subset(year %in% c(1998:2012)) %>%
  fcm()

set.seed(1069)  
text_fcm_hk_98_s <- fcm_select(text_fcm_hk_98, pattern = names(topfeatures(text_fcm_hk_98, n = 30)))
pdf("network_hk_98.pdf", family = "CNS1")
textplot_network(text_fcm_hk_98_s)
dev.off()

# plot different network for 1998-2012 and 2013-2018
text_fcm_hk_13 <- text_dfm_hk %>% #subset using dfm_subset
  dfm_subset(year >= 2013) %>%
  fcm()

set.seed(1069)  
text_fcm_hk_13_s <- fcm_select(text_fcm_hk_13, pattern = names(topfeatures(text_fcm_hk_13, n = 30)))
pdf("network_hk_13.pdf", family = "CNS1")
textplot_network(text_fcm_hk_13_s)
dev.off()



```



```{r keyness}

tstat_key_hk <- textstat_keyness(text_dfm_hk, 
                              target = docvars(text_dfm_hk, "year") >= 2013)
attr(tstat_key_hk, "documents") <- c("2013-2018", '1998-2012')

pdf("keyness_hk.pdf", family = "CNS1")
textplot_keyness(tstat_key_hk)
dev.off()

tstat_key_tw <- textstat_keyness(text_dfm_tw, 
                              target = docvars(text_dfm_tw, "year") >= 2013)
attr(tstat_key_tw, "documents") <- c("2013-2018", '1998-2012')


pdf("keyness_tw.pdf", family = "CNS1")
textplot_keyness(tstat_key_tw)
dev.off()

```

```{r collocation}

text_col_hk <- textstat_collocations(text_token_hk, size = 2, min_count = 20)
knitr::kable(top_n(text_col_hk, 10, wt = count))

text_token_hk %>% # subset 2013, do the collocation analysis and select top 10 counts
  tokens_subset(year < 2013) %>%
  textstat_collocations(size = 2) %>%
  top_n(10, wt = count) %>%
  kable()

text_token_hk %>% # subset 2013, do the collocation analysis and select top 10 counts
  tokens_subset(year >= 2013) %>%
  textstat_collocations(size = 2) %>%
  top_n(10, wt = count) %>%
  kable()

```



